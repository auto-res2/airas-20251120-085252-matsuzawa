run_id: comparative-1-iter1-Qwen3-0.6B-gsm8k
method: comparative
model:
  name: Qwen/Qwen3-0.6B
  precision: fp16
  adapter:
    type: lora
    rank: 8
    blocks: 32
dataset:
  name: gsm8k
  split:
    train: main/train
    validation: main/test
  preprocessing:
    prompt_style: chain-of-thought
    max_length: 2048
training:
  epochs: 3
  physical_batch_size: 8
  gradient_accumulation_steps: 2
  learning_rate_base: 2e-5
  optimizer:
    name: adamw
    betas: [0.9, 0.999]
    weight_decay: 0.01
  scheduler:
    name: cosine
    warmup_steps: 0
  pac_turbo:            # original PAC-TURBO knobs
    delta: 0.05
    rho: 0.9
    ga_max: 8
evaluation:
  eval_every_updates: 100
  metrics: [exact_match, energy_to_15_em]
hardware:
  gpu_type: A100
  num_gpus: 1
optuna:
  n_trials: 24
  direction: maximize
  search_space:
    training.learning_rate_base:
      type: loguniform
      low: 1e-5
      high: 5e-5
    pac_turbo.ga_max:
      type: int
      low: 2
      high: 10
      step: 2
    pac_turbo.rho:
      type: uniform
      low: 0.85
      high: 0.95